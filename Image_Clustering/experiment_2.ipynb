{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "np.random.seed(10)\n",
    "\n",
    "from time import time\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras import callbacks\n",
    "from keras.initializers import VarianceScaling\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Reshape, Conv2DTranspose\n",
    "\n",
    "from encoder_function import autoencoder, autoencoderConv2D_1, autoencoderConv2D_2, ClusteringLayer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5373, 784)\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import os\n",
    "root_path = './label_6/'\n",
    "images = []\n",
    "labels = []\n",
    "for folder in os.listdir(root_path):\n",
    "    if 'DS_Store' in folder:\n",
    "        continue\n",
    "    for f_name in os.listdir(os.path.join(root_path, folder)):\n",
    "        if 'DS_Store' in f_name:\n",
    "            continue\n",
    "        image = cv2.imread(os.path.join(root_path, folder, f_name))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        image = cv2.resize(image, (28,28))\n",
    "        image = image.astype(\"float\") / 255.0\n",
    "        image = img_to_array(image)\n",
    "        images.append(image)\n",
    "        labels.append(folder)\n",
    "\n",
    "images = np.array(images)\n",
    "x = images.reshape((images.shape[0], -1))\n",
    "y = labels\n",
    "print(x.shape)\n",
    "n_clusters = len(np.unique(y))\n",
    "print(n_clusters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline K Means Clustering Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=n_clusters, n_init=6, n_jobs=-1)\n",
    "y_pred_kmeans = kmeans.fit_predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 3, 3, ..., 1, 4, 5], dtype=int32)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43605725889679814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.12347674555865912"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(metrics.mutual_info_score(y,y_pred_kmeans))\n",
    "metrics.adjusted_rand_score(y,y_pred_kmeans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-train Auto-encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = [x.shape[-1], 500, 500, 2000, 6]\n",
    "init = VarianceScaling(scale=1. / 3., mode='fan_in',distribution='uniform')\n",
    "pretrain_optimizer = SGD(lr=0.01, momentum=0.9)\n",
    "pretrain_epochs = 600\n",
    "batch_size = 200\n",
    "save_dir = './results/screen_clustering/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "5373/5373 [==============================] - 1s 244us/step - loss: 0.5756\n",
      "Epoch 2/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.5699\n",
      "Epoch 3/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.5634\n",
      "Epoch 4/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.5563\n",
      "Epoch 5/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.5471\n",
      "Epoch 6/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.5248\n",
      "Epoch 7/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.3492\n",
      "Epoch 8/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1363\n",
      "Epoch 9/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1269\n",
      "Epoch 10/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1261\n",
      "Epoch 11/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1260\n",
      "Epoch 12/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1259\n",
      "Epoch 13/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1259\n",
      "Epoch 14/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1258\n",
      "Epoch 15/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1258\n",
      "Epoch 16/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1258\n",
      "Epoch 17/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1257\n",
      "Epoch 18/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1257\n",
      "Epoch 19/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1257\n",
      "Epoch 20/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1257\n",
      "Epoch 21/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1257\n",
      "Epoch 22/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1257\n",
      "Epoch 23/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1256\n",
      "Epoch 24/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1256\n",
      "Epoch 25/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.1256\n",
      "Epoch 26/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1256\n",
      "Epoch 27/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1256\n",
      "Epoch 28/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.1256\n",
      "Epoch 29/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.1256\n",
      "Epoch 30/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1256\n",
      "Epoch 31/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1256\n",
      "Epoch 32/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.1256\n",
      "Epoch 33/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1256\n",
      "Epoch 34/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1256\n",
      "Epoch 35/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1255\n",
      "Epoch 36/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1255\n",
      "Epoch 37/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1255\n",
      "Epoch 38/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1255\n",
      "Epoch 39/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.1255\n",
      "Epoch 40/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1255\n",
      "Epoch 41/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1255\n",
      "Epoch 42/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1255\n",
      "Epoch 43/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1255\n",
      "Epoch 44/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1255\n",
      "Epoch 45/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1255\n",
      "Epoch 46/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1255\n",
      "Epoch 47/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1255\n",
      "Epoch 48/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1255\n",
      "Epoch 49/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1255\n",
      "Epoch 50/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1255\n",
      "Epoch 51/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1254\n",
      "Epoch 52/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1254\n",
      "Epoch 53/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1254\n",
      "Epoch 54/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1254\n",
      "Epoch 55/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1254\n",
      "Epoch 56/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1254\n",
      "Epoch 57/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1254\n",
      "Epoch 58/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1254\n",
      "Epoch 59/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1254\n",
      "Epoch 60/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.1254\n",
      "Epoch 61/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1254\n",
      "Epoch 62/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1254\n",
      "Epoch 63/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1254\n",
      "Epoch 64/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1254\n",
      "Epoch 65/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1254\n",
      "Epoch 66/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1254\n",
      "Epoch 67/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1254\n",
      "Epoch 68/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1254\n",
      "Epoch 69/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.1254\n",
      "Epoch 70/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.1254\n",
      "Epoch 71/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1253\n",
      "Epoch 72/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1253\n",
      "Epoch 73/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1253\n",
      "Epoch 74/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1253\n",
      "Epoch 75/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.1253\n",
      "Epoch 76/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1253\n",
      "Epoch 77/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1253\n",
      "Epoch 78/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1253\n",
      "Epoch 79/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.1253\n",
      "Epoch 80/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1253\n",
      "Epoch 81/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.1253\n",
      "Epoch 82/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1253\n",
      "Epoch 83/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1253\n",
      "Epoch 84/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1253\n",
      "Epoch 85/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.1253\n",
      "Epoch 86/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1253\n",
      "Epoch 87/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1253\n",
      "Epoch 88/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1253\n",
      "Epoch 89/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1253\n",
      "Epoch 90/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1252\n",
      "Epoch 91/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1252\n",
      "Epoch 92/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1252\n",
      "Epoch 93/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.1252\n",
      "Epoch 94/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1252\n",
      "Epoch 95/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1252\n",
      "Epoch 96/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1252\n",
      "Epoch 97/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1252\n",
      "Epoch 98/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.1252\n",
      "Epoch 99/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.1252\n",
      "Epoch 100/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1252\n",
      "Epoch 101/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1252\n",
      "Epoch 102/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.1252\n",
      "Epoch 103/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1252\n",
      "Epoch 104/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1251\n",
      "Epoch 105/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1251\n",
      "Epoch 106/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1251\n",
      "Epoch 107/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1251\n",
      "Epoch 108/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1251\n",
      "Epoch 109/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1251\n",
      "Epoch 110/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1251\n",
      "Epoch 111/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1251\n",
      "Epoch 112/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1251\n",
      "Epoch 113/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1251\n",
      "Epoch 114/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1251\n",
      "Epoch 115/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1250\n",
      "Epoch 116/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1250\n",
      "Epoch 117/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1250\n",
      "Epoch 118/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1250\n",
      "Epoch 119/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1250\n",
      "Epoch 120/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1250\n",
      "Epoch 121/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1250\n",
      "Epoch 122/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1249\n",
      "Epoch 123/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1249\n",
      "Epoch 124/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1249\n",
      "Epoch 125/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1249\n",
      "Epoch 126/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1249\n",
      "Epoch 127/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1248\n",
      "Epoch 128/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1248\n",
      "Epoch 129/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1248\n",
      "Epoch 130/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.1247\n",
      "Epoch 131/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1247\n",
      "Epoch 132/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1247\n",
      "Epoch 133/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1246\n",
      "Epoch 134/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1246\n",
      "Epoch 135/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1245\n",
      "Epoch 136/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1245\n",
      "Epoch 137/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1244\n",
      "Epoch 138/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1243\n",
      "Epoch 139/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1242\n",
      "Epoch 140/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1241\n",
      "Epoch 141/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1240\n",
      "Epoch 142/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1239\n",
      "Epoch 143/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1237\n",
      "Epoch 144/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1235\n",
      "Epoch 145/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1233\n",
      "Epoch 146/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1230\n",
      "Epoch 147/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1227\n",
      "Epoch 148/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1222\n",
      "Epoch 149/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1217\n",
      "Epoch 150/600\n",
      "5373/5373 [==============================] - 0s 26us/step - loss: 0.1211\n",
      "Epoch 151/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1204\n",
      "Epoch 152/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1196\n",
      "Epoch 153/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1187\n",
      "Epoch 154/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1177\n",
      "Epoch 155/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1166\n",
      "Epoch 156/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1155\n",
      "Epoch 157/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.1145\n",
      "Epoch 158/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.1135\n",
      "Epoch 159/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.1126\n",
      "Epoch 160/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1117\n",
      "Epoch 161/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1110\n",
      "Epoch 162/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1102\n",
      "Epoch 163/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1096\n",
      "Epoch 164/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.1091\n",
      "Epoch 165/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1086\n",
      "Epoch 166/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1081\n",
      "Epoch 167/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1078\n",
      "Epoch 168/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1074\n",
      "Epoch 169/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1072\n",
      "Epoch 170/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.1069\n",
      "Epoch 171/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.1067\n",
      "Epoch 172/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.1065\n",
      "Epoch 173/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.1063\n",
      "Epoch 174/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1062\n",
      "Epoch 175/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1060\n",
      "Epoch 176/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1059\n",
      "Epoch 177/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1058\n",
      "Epoch 178/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1057\n",
      "Epoch 179/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1056\n",
      "Epoch 180/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1055\n",
      "Epoch 181/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1054\n",
      "Epoch 182/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1053\n",
      "Epoch 183/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1052\n",
      "Epoch 184/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1051\n",
      "Epoch 185/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.1050\n",
      "Epoch 186/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.1049\n",
      "Epoch 187/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1048\n",
      "Epoch 188/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1047\n",
      "Epoch 189/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1046\n",
      "Epoch 190/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1045\n",
      "Epoch 191/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1044\n",
      "Epoch 192/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1043\n",
      "Epoch 193/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1042\n",
      "Epoch 194/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.1040\n",
      "Epoch 195/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.1039\n",
      "Epoch 196/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1038\n",
      "Epoch 197/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1036\n",
      "Epoch 198/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1035\n",
      "Epoch 199/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1033\n",
      "Epoch 200/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1032\n",
      "Epoch 201/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1029\n",
      "Epoch 202/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.1028\n",
      "Epoch 203/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1025\n",
      "Epoch 204/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.1023\n",
      "Epoch 205/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.1021\n",
      "Epoch 206/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1018\n",
      "Epoch 207/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1016\n",
      "Epoch 208/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1013\n",
      "Epoch 209/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.1009\n",
      "Epoch 210/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1006\n",
      "Epoch 211/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.1003\n",
      "Epoch 212/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0999\n",
      "Epoch 213/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0996\n",
      "Epoch 214/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0993\n",
      "Epoch 215/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0989\n",
      "Epoch 216/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0986\n",
      "Epoch 217/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0983\n",
      "Epoch 218/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0980\n",
      "Epoch 219/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0977\n",
      "Epoch 220/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0975\n",
      "Epoch 221/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0972\n",
      "Epoch 222/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0970\n",
      "Epoch 223/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0968\n",
      "Epoch 224/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0966\n",
      "Epoch 225/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0964\n",
      "Epoch 226/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0963\n",
      "Epoch 227/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0961\n",
      "Epoch 228/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0960\n",
      "Epoch 229/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0958\n",
      "Epoch 230/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0957\n",
      "Epoch 231/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0956\n",
      "Epoch 232/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0955\n",
      "Epoch 233/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0954\n",
      "Epoch 234/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0953\n",
      "Epoch 235/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0952\n",
      "Epoch 236/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0952\n",
      "Epoch 237/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0951\n",
      "Epoch 238/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0950\n",
      "Epoch 239/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0949\n",
      "Epoch 240/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0949\n",
      "Epoch 241/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0948\n",
      "Epoch 242/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0948\n",
      "Epoch 243/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0947\n",
      "Epoch 244/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0947\n",
      "Epoch 245/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0946\n",
      "Epoch 246/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0946\n",
      "Epoch 247/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0945\n",
      "Epoch 248/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0945\n",
      "Epoch 249/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0945\n",
      "Epoch 250/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0944\n",
      "Epoch 251/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0944\n",
      "Epoch 252/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0944\n",
      "Epoch 253/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0943\n",
      "Epoch 254/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0943\n",
      "Epoch 255/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0943\n",
      "Epoch 256/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0942\n",
      "Epoch 257/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0942\n",
      "Epoch 258/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0942\n",
      "Epoch 259/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0941\n",
      "Epoch 260/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0941\n",
      "Epoch 261/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0941\n",
      "Epoch 262/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0941\n",
      "Epoch 263/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0940\n",
      "Epoch 264/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0940\n",
      "Epoch 265/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0940\n",
      "Epoch 266/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0940\n",
      "Epoch 267/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0939\n",
      "Epoch 268/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0939\n",
      "Epoch 269/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0939\n",
      "Epoch 270/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0939\n",
      "Epoch 271/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0938\n",
      "Epoch 272/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0938\n",
      "Epoch 273/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0938\n",
      "Epoch 274/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0937\n",
      "Epoch 275/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0937\n",
      "Epoch 276/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0937\n",
      "Epoch 277/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0937\n",
      "Epoch 278/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0936\n",
      "Epoch 279/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0936\n",
      "Epoch 280/600\n",
      "5373/5373 [==============================] - 0s 23us/step - loss: 0.0936\n",
      "Epoch 281/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0935\n",
      "Epoch 282/600\n",
      "5373/5373 [==============================] - 0s 23us/step - loss: 0.0935\n",
      "Epoch 283/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0935\n",
      "Epoch 284/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0935\n",
      "Epoch 285/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0934\n",
      "Epoch 286/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0934\n",
      "Epoch 287/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0934\n",
      "Epoch 288/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0933\n",
      "Epoch 289/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0933\n",
      "Epoch 290/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0933\n",
      "Epoch 291/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0932\n",
      "Epoch 292/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0932\n",
      "Epoch 293/600\n",
      "5373/5373 [==============================] - 0s 23us/step - loss: 0.0932\n",
      "Epoch 294/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0931\n",
      "Epoch 295/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0931\n",
      "Epoch 296/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0931\n",
      "Epoch 297/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0930\n",
      "Epoch 298/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0930\n",
      "Epoch 299/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0929\n",
      "Epoch 300/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0929\n",
      "Epoch 301/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0928\n",
      "Epoch 302/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0928\n",
      "Epoch 303/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0927\n",
      "Epoch 304/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0927\n",
      "Epoch 305/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0926\n",
      "Epoch 306/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0926\n",
      "Epoch 307/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0925\n",
      "Epoch 308/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0924\n",
      "Epoch 309/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0923\n",
      "Epoch 310/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0923\n",
      "Epoch 311/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0922\n",
      "Epoch 312/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0921\n",
      "Epoch 313/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0920\n",
      "Epoch 314/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0919\n",
      "Epoch 315/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0918\n",
      "Epoch 316/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0916\n",
      "Epoch 317/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0915\n",
      "Epoch 318/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0914\n",
      "Epoch 319/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0912\n",
      "Epoch 320/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0910\n",
      "Epoch 321/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0909\n",
      "Epoch 322/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0907\n",
      "Epoch 323/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0905\n",
      "Epoch 324/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0903\n",
      "Epoch 325/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0900\n",
      "Epoch 326/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0898\n",
      "Epoch 327/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0896\n",
      "Epoch 328/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0893\n",
      "Epoch 329/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0891\n",
      "Epoch 330/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0888\n",
      "Epoch 331/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0886\n",
      "Epoch 332/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0884\n",
      "Epoch 333/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0882\n",
      "Epoch 334/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0880\n",
      "Epoch 335/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0877\n",
      "Epoch 336/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0876\n",
      "Epoch 337/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0874\n",
      "Epoch 338/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0872\n",
      "Epoch 339/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0870\n",
      "Epoch 340/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0869\n",
      "Epoch 341/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0867\n",
      "Epoch 342/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0865\n",
      "Epoch 343/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0864\n",
      "Epoch 344/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0863\n",
      "Epoch 345/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0861\n",
      "Epoch 346/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0860\n",
      "Epoch 347/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0859\n",
      "Epoch 348/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0858\n",
      "Epoch 349/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0857\n",
      "Epoch 350/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0856\n",
      "Epoch 351/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0855\n",
      "Epoch 352/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0854\n",
      "Epoch 353/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0853\n",
      "Epoch 354/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0853\n",
      "Epoch 355/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0852\n",
      "Epoch 356/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0851\n",
      "Epoch 357/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0851\n",
      "Epoch 358/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0850\n",
      "Epoch 359/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0849\n",
      "Epoch 360/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0849\n",
      "Epoch 361/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0848\n",
      "Epoch 362/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0848\n",
      "Epoch 363/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0847\n",
      "Epoch 364/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0847\n",
      "Epoch 365/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0846\n",
      "Epoch 366/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0846\n",
      "Epoch 367/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0845\n",
      "Epoch 368/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0845\n",
      "Epoch 369/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0844\n",
      "Epoch 370/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0844\n",
      "Epoch 371/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0844\n",
      "Epoch 372/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0843\n",
      "Epoch 373/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0843\n",
      "Epoch 374/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0843\n",
      "Epoch 375/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0842\n",
      "Epoch 376/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0842\n",
      "Epoch 377/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0842\n",
      "Epoch 378/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0841\n",
      "Epoch 379/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0841\n",
      "Epoch 380/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0841\n",
      "Epoch 381/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0840\n",
      "Epoch 382/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0840\n",
      "Epoch 383/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0840\n",
      "Epoch 384/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0839\n",
      "Epoch 385/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0839\n",
      "Epoch 386/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0839\n",
      "Epoch 387/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0838\n",
      "Epoch 388/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0838\n",
      "Epoch 389/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0838\n",
      "Epoch 390/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0838\n",
      "Epoch 391/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0837\n",
      "Epoch 392/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0837\n",
      "Epoch 393/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0837\n",
      "Epoch 394/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0836\n",
      "Epoch 395/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0836\n",
      "Epoch 396/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0836\n",
      "Epoch 397/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0836\n",
      "Epoch 398/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0835\n",
      "Epoch 399/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0835\n",
      "Epoch 400/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0835\n",
      "Epoch 401/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0834\n",
      "Epoch 402/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0834\n",
      "Epoch 403/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0834\n",
      "Epoch 404/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0833\n",
      "Epoch 405/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0833\n",
      "Epoch 406/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0833\n",
      "Epoch 407/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0833\n",
      "Epoch 408/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0833\n",
      "Epoch 409/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0832\n",
      "Epoch 410/600\n",
      "5373/5373 [==============================] - 0s 23us/step - loss: 0.0832\n",
      "Epoch 411/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0832\n",
      "Epoch 412/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0831\n",
      "Epoch 413/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0831\n",
      "Epoch 414/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0831\n",
      "Epoch 415/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0831\n",
      "Epoch 416/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0830\n",
      "Epoch 417/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0830\n",
      "Epoch 418/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0830\n",
      "Epoch 419/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0829\n",
      "Epoch 420/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0829\n",
      "Epoch 421/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0829\n",
      "Epoch 422/600\n",
      "5373/5373 [==============================] - 0s 19us/step - loss: 0.0829\n",
      "Epoch 423/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0828\n",
      "Epoch 424/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0828\n",
      "Epoch 425/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0828\n",
      "Epoch 426/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0827\n",
      "Epoch 427/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0827\n",
      "Epoch 428/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0827\n",
      "Epoch 429/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0826\n",
      "Epoch 430/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0826\n",
      "Epoch 431/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0826\n",
      "Epoch 432/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0826\n",
      "Epoch 433/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0825\n",
      "Epoch 434/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0825\n",
      "Epoch 435/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0824\n",
      "Epoch 436/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0824\n",
      "Epoch 437/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0824\n",
      "Epoch 438/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0823\n",
      "Epoch 439/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0823\n",
      "Epoch 440/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0823\n",
      "Epoch 441/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0822\n",
      "Epoch 442/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0822\n",
      "Epoch 443/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0822\n",
      "Epoch 444/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0821\n",
      "Epoch 445/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0821\n",
      "Epoch 446/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0820\n",
      "Epoch 447/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0820\n",
      "Epoch 448/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0820\n",
      "Epoch 449/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0819\n",
      "Epoch 450/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0819\n",
      "Epoch 451/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0819\n",
      "Epoch 452/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0818\n",
      "Epoch 453/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0818\n",
      "Epoch 454/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0817\n",
      "Epoch 455/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0817\n",
      "Epoch 456/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0816\n",
      "Epoch 457/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0816\n",
      "Epoch 458/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0815\n",
      "Epoch 459/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0815\n",
      "Epoch 460/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0814\n",
      "Epoch 461/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0814\n",
      "Epoch 462/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0813\n",
      "Epoch 463/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0813\n",
      "Epoch 464/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0812\n",
      "Epoch 465/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0811\n",
      "Epoch 466/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0811\n",
      "Epoch 467/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0810\n",
      "Epoch 468/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0809\n",
      "Epoch 469/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0809\n",
      "Epoch 470/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0808\n",
      "Epoch 471/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0807\n",
      "Epoch 472/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0806\n",
      "Epoch 473/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0806\n",
      "Epoch 474/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0805\n",
      "Epoch 475/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0804\n",
      "Epoch 476/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0803\n",
      "Epoch 477/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0802\n",
      "Epoch 478/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0801\n",
      "Epoch 479/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0801\n",
      "Epoch 480/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0800\n",
      "Epoch 481/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0799\n",
      "Epoch 482/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0798\n",
      "Epoch 483/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0797\n",
      "Epoch 484/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0796\n",
      "Epoch 485/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0795\n",
      "Epoch 486/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0794\n",
      "Epoch 487/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0794\n",
      "Epoch 488/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0793\n",
      "Epoch 489/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0792\n",
      "Epoch 490/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0791\n",
      "Epoch 491/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0791\n",
      "Epoch 492/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0790\n",
      "Epoch 493/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0789\n",
      "Epoch 494/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0788\n",
      "Epoch 495/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0788\n",
      "Epoch 496/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0787\n",
      "Epoch 497/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0786\n",
      "Epoch 498/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0786\n",
      "Epoch 499/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0785\n",
      "Epoch 500/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0784\n",
      "Epoch 501/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0784\n",
      "Epoch 502/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0783\n",
      "Epoch 503/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0783\n",
      "Epoch 504/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0782\n",
      "Epoch 505/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0782\n",
      "Epoch 506/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0781\n",
      "Epoch 507/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0780\n",
      "Epoch 508/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0780\n",
      "Epoch 509/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0779\n",
      "Epoch 510/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0779\n",
      "Epoch 511/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0778\n",
      "Epoch 512/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0778\n",
      "Epoch 513/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0777\n",
      "Epoch 514/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0777\n",
      "Epoch 515/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0777\n",
      "Epoch 516/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0776\n",
      "Epoch 517/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0776\n",
      "Epoch 518/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0775\n",
      "Epoch 519/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0775\n",
      "Epoch 520/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0774\n",
      "Epoch 521/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0774\n",
      "Epoch 522/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0773\n",
      "Epoch 523/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0773\n",
      "Epoch 524/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0773\n",
      "Epoch 525/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0772\n",
      "Epoch 526/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0772\n",
      "Epoch 527/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0771\n",
      "Epoch 528/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0771\n",
      "Epoch 529/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0771\n",
      "Epoch 530/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0770\n",
      "Epoch 531/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0770\n",
      "Epoch 532/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0769\n",
      "Epoch 533/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0769\n",
      "Epoch 534/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0769\n",
      "Epoch 535/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0768\n",
      "Epoch 536/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0768\n",
      "Epoch 537/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0768\n",
      "Epoch 538/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0767\n",
      "Epoch 539/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0767\n",
      "Epoch 540/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0766\n",
      "Epoch 541/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0766\n",
      "Epoch 542/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0766\n",
      "Epoch 543/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0765\n",
      "Epoch 544/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0765\n",
      "Epoch 545/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0765\n",
      "Epoch 546/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0764\n",
      "Epoch 547/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0764\n",
      "Epoch 548/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0764\n",
      "Epoch 549/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0763\n",
      "Epoch 550/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0763\n",
      "Epoch 551/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0763\n",
      "Epoch 552/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0763\n",
      "Epoch 553/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0762\n",
      "Epoch 554/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0762\n",
      "Epoch 555/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0761\n",
      "Epoch 556/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0761\n",
      "Epoch 557/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0761\n",
      "Epoch 558/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0761\n",
      "Epoch 559/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0760\n",
      "Epoch 560/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0760\n",
      "Epoch 561/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0760\n",
      "Epoch 562/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0759\n",
      "Epoch 563/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0759\n",
      "Epoch 564/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0759\n",
      "Epoch 565/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0758\n",
      "Epoch 566/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0758\n",
      "Epoch 567/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0758\n",
      "Epoch 568/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0757\n",
      "Epoch 569/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0757\n",
      "Epoch 570/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0757\n",
      "Epoch 571/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0757\n",
      "Epoch 572/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0756\n",
      "Epoch 573/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0756\n",
      "Epoch 574/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0756\n",
      "Epoch 575/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0756\n",
      "Epoch 576/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0755\n",
      "Epoch 577/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0755\n",
      "Epoch 578/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0755\n",
      "Epoch 579/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0754\n",
      "Epoch 580/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0754\n",
      "Epoch 581/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0754\n",
      "Epoch 582/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0754\n",
      "Epoch 583/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0753\n",
      "Epoch 584/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0753\n",
      "Epoch 585/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0753\n",
      "Epoch 586/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0752\n",
      "Epoch 587/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0752\n",
      "Epoch 588/600\n",
      "5373/5373 [==============================] - 0s 20us/step - loss: 0.0752\n",
      "Epoch 589/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0751\n",
      "Epoch 590/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0751\n",
      "Epoch 591/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0751\n",
      "Epoch 592/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0750\n",
      "Epoch 593/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0750\n",
      "Epoch 594/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0750\n",
      "Epoch 595/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0750\n",
      "Epoch 596/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0749\n",
      "Epoch 597/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0749\n",
      "Epoch 598/600\n",
      "5373/5373 [==============================] - 0s 22us/step - loss: 0.0749\n",
      "Epoch 599/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0748\n",
      "Epoch 600/600\n",
      "5373/5373 [==============================] - 0s 21us/step - loss: 0.0748\n"
     ]
    }
   ],
   "source": [
    "autoencoder1, encoder1 = autoencoder(dims, init=init)\n",
    "autoencoder1.compile(optimizer=pretrain_optimizer, loss='mse')\n",
    "autoencoder1.fit(x, x, batch_size=batch_size, epochs=pretrain_epochs) #, callbacks=cb)\n",
    "autoencoder1.save_weights(save_dir + '/ae_weights.h5')\n",
    "autoencoder1.load_weights(save_dir + '/ae_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_layer = ClusteringLayer(n_clusters, name='clustering')(encoder1.output)\n",
    "model = Model(inputs=encoder1.input, outputs=clustering_layer)\n",
    "model.compile(optimizer=SGD(0.01, 0.9), loss='kld')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step1. initialize cluster centers with kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering NMI after encoding:0.295065\n",
      "Clustering ARI after encoding:0.074433\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=n_clusters, n_init=6)\n",
    "y_pred = kmeans.fit_predict(encoder1.predict(x))\n",
    "\n",
    "y_pred_last = np.copy(y_pred)\n",
    "print('Clustering NMI after encoding:%f'% metrics.mutual_info_score(y, y_pred_last))\n",
    "print('Clustering ARI after encoding:%f'% metrics.adjusted_rand_score(y, y_pred_last))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_layer(name='clustering').set_weights([kmeans.cluster_centers_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step2.Deep Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iter 0: nmi = 0.34749, ari = 0.07077', ' ; loss=', 0)\n",
      "('Iter 140: nmi = 0.34225, ari = 0.07160', ' ; loss=', 0.04744)\n",
      "('Iter 280: nmi = 0.35346, ari = 0.09108', ' ; loss=', 0.13827)\n",
      "('Iter 420: nmi = 0.34572, ari = 0.07966', ' ; loss=', 0.18434)\n",
      "('Iter 560: nmi = 0.34961, ari = 0.07866', ' ; loss=', 0.25351)\n",
      "('Iter 700: nmi = 0.34420, ari = 0.07750', ' ; loss=', 0.10131)\n",
      "('Iter 840: nmi = 0.32646, ari = 0.07448', ' ; loss=', 0.07995)\n",
      "('Iter 980: nmi = 0.30735, ari = 0.06782', ' ; loss=', 0.48376)\n",
      "('Iter 1120: nmi = 0.30934, ari = 0.08077', ' ; loss=', 0.13933)\n",
      "('Iter 1260: nmi = 0.32932, ari = 0.09968', ' ; loss=', 0.38518)\n",
      "('Iter 1400: nmi = 0.30948, ari = 0.09539', ' ; loss=', 0.30549)\n",
      "('Iter 1540: nmi = 0.32764, ari = 0.10475', ' ; loss=', 0.05691)\n",
      "('Iter 1680: nmi = 0.34407, ari = 0.11653', ' ; loss=', 0.08286)\n",
      "('Iter 1820: nmi = 0.35134, ari = 0.12103', ' ; loss=', 0.22678)\n",
      "('Iter 1960: nmi = 0.34070, ari = 0.11497', ' ; loss=', 0.11848)\n",
      "('Iter 2100: nmi = 0.35669, ari = 0.10259', ' ; loss=', 0.24585)\n",
      "('Iter 2240: nmi = 0.36364, ari = 0.10789', ' ; loss=', 0.13665)\n",
      "('Iter 2380: nmi = 0.36623, ari = 0.11192', ' ; loss=', 0.09462)\n",
      "('Iter 2520: nmi = 0.35509, ari = 0.10656', ' ; loss=', 0.23145)\n",
      "('Iter 2660: nmi = 0.36639, ari = 0.11815', ' ; loss=', 0.17888)\n",
      "('Iter 2800: nmi = 0.36007, ari = 0.11333', ' ; loss=', 0.14102)\n",
      "('Iter 2940: nmi = 0.35842, ari = 0.11363', ' ; loss=', 0.08935)\n",
      "('Iter 3080: nmi = 0.33165, ari = 0.09166', ' ; loss=', 0.33477)\n",
      "('Iter 3220: nmi = 0.31939, ari = 0.08861', ' ; loss=', 0.13064)\n",
      "('Iter 3360: nmi = 0.32493, ari = 0.09271', ' ; loss=', 0.12838)\n",
      "('Iter 3500: nmi = 0.32574, ari = 0.09486', ' ; loss=', 0.111)\n",
      "('Iter 3640: nmi = 0.32178, ari = 0.09053', ' ; loss=', 0.0891)\n",
      "('Iter 3780: nmi = 0.31188, ari = 0.08040', ' ; loss=', 0.08204)\n",
      "('Iter 3920: nmi = 0.30621, ari = 0.07741', ' ; loss=', 0.07218)\n",
      "('Iter 4060: nmi = 0.30622, ari = 0.07693', ' ; loss=', 0.15102)\n",
      "('Iter 4200: nmi = 0.30612, ari = 0.07663', ' ; loss=', 0.13135)\n",
      "('Iter 4340: nmi = 0.30959, ari = 0.08027', ' ; loss=', 0.13325)\n",
      "('Iter 4480: nmi = 0.30795, ari = 0.08007', ' ; loss=', 0.07823)\n",
      "('Iter 4620: nmi = 0.31406, ari = 0.08761', ' ; loss=', 0.07825)\n",
      "('Iter 4760: nmi = 0.31719, ari = 0.08759', ' ; loss=', 0.11989)\n",
      "('Iter 4900: nmi = 0.31557, ari = 0.08804', ' ; loss=', 0.08356)\n",
      "('Iter 5040: nmi = 0.31668, ari = 0.08926', ' ; loss=', 0.12949)\n",
      "('Iter 5180: nmi = 0.30939, ari = 0.08097', ' ; loss=', 0.10915)\n",
      "('Iter 5320: nmi = 0.31134, ari = 0.08916', ' ; loss=', 0.11289)\n",
      "('Iter 5460: nmi = 0.31276, ari = 0.09122', ' ; loss=', 0.11989)\n",
      "('Iter 5600: nmi = 0.31178, ari = 0.09339', ' ; loss=', 0.07442)\n",
      "('Iter 5740: nmi = 0.31658, ari = 0.10262', ' ; loss=', 0.13165)\n",
      "('Iter 5880: nmi = 0.31716, ari = 0.10408', ' ; loss=', 0.13912)\n",
      "('Iter 6020: nmi = 0.33693, ari = 0.10382', ' ; loss=', 0.41466)\n",
      "('Iter 6160: nmi = 0.35407, ari = 0.10868', ' ; loss=', 0.08792)\n",
      "('Iter 6300: nmi = 0.35646, ari = 0.11118', ' ; loss=', 0.09808)\n",
      "('Iter 6440: nmi = 0.36355, ari = 0.11388', ' ; loss=', 0.10753)\n",
      "('Iter 6580: nmi = 0.37145, ari = 0.11658', ' ; loss=', 0.09383)\n",
      "('Iter 6720: nmi = 0.37724, ari = 0.12106', ' ; loss=', 0.09427)\n",
      "('Iter 6860: nmi = 0.39032, ari = 0.13038', ' ; loss=', 0.15174)\n",
      "('Iter 7000: nmi = 0.39671, ari = 0.13481', ' ; loss=', 0.08706)\n",
      "('Iter 7140: nmi = 0.40428, ari = 0.14072', ' ; loss=', 0.10816)\n",
      "('Iter 7280: nmi = 0.39196, ari = 0.13928', ' ; loss=', 0.10214)\n",
      "('Iter 7420: nmi = 0.40103, ari = 0.14014', ' ; loss=', 0.09526)\n",
      "('Iter 7560: nmi = 0.39940, ari = 0.13961', ' ; loss=', 0.19369)\n",
      "('Iter 7700: nmi = 0.41390, ari = 0.14674', ' ; loss=', 0.10524)\n",
      "('Iter 7840: nmi = 0.41929, ari = 0.15051', ' ; loss=', 0.07443)\n",
      "('Iter 7980: nmi = 0.41907, ari = 0.15001', ' ; loss=', 0.08438)\n",
      "('Iter 8120: nmi = 0.41767, ari = 0.14957', ' ; loss=', 0.06585)\n",
      "('Iter 8260: nmi = 0.39223, ari = 0.13932', ' ; loss=', 0.10361)\n",
      "('Iter 8400: nmi = 0.40846, ari = 0.14953', ' ; loss=', 0.19508)\n",
      "('Iter 8540: nmi = 0.41531, ari = 0.15453', ' ; loss=', 0.09217)\n",
      "('Iter 8680: nmi = 0.40936, ari = 0.15663', ' ; loss=', 0.07503)\n",
      "('Iter 8820: nmi = 0.42695, ari = 0.16023', ' ; loss=', 0.11963)\n",
      "('Iter 8960: nmi = 0.43555, ari = 0.16305', ' ; loss=', 0.11229)\n",
      "('Iter 9100: nmi = 0.43891, ari = 0.17205', ' ; loss=', 0.15517)\n",
      "('Iter 9240: nmi = 0.45479, ari = 0.18012', ' ; loss=', 0.10048)\n",
      "('Iter 9380: nmi = 0.45558, ari = 0.18047', ' ; loss=', 0.06884)\n",
      "('Iter 9520: nmi = 0.46092, ari = 0.17657', ' ; loss=', 0.09756)\n",
      "('Iter 9660: nmi = 0.45799, ari = 0.17643', ' ; loss=', 0.1439)\n",
      "('Iter 9800: nmi = 0.45123, ari = 0.17191', ' ; loss=', 0.11828)\n",
      "('Iter 9940: nmi = 0.41451, ari = 0.15604', ' ; loss=', 0.10654)\n",
      "('Iter 10080: nmi = 0.41368, ari = 0.15654', ' ; loss=', 0.09476)\n",
      "('Iter 10220: nmi = 0.39354, ari = 0.14573', ' ; loss=', 0.07996)\n",
      "('Iter 10360: nmi = 0.37174, ari = 0.13538', ' ; loss=', 0.15173)\n",
      "('Iter 10500: nmi = 0.37255, ari = 0.13694', ' ; loss=', 0.15986)\n",
      "('Iter 10640: nmi = 0.37303, ari = 0.13791', ' ; loss=', 0.14176)\n",
      "('Iter 10780: nmi = 0.36849, ari = 0.13852', ' ; loss=', 0.42294)\n",
      "('Iter 10920: nmi = 0.37446, ari = 0.14330', ' ; loss=', 0.10588)\n",
      "('Iter 11060: nmi = 0.37533, ari = 0.14638', ' ; loss=', 0.06835)\n",
      "('Iter 11200: nmi = 0.38052, ari = 0.14904', ' ; loss=', 0.09392)\n",
      "('Iter 11340: nmi = 0.38119, ari = 0.14901', ' ; loss=', 0.10618)\n",
      "('Iter 11480: nmi = 0.38201, ari = 0.14915', ' ; loss=', 0.11372)\n",
      "('Iter 11620: nmi = 0.38631, ari = 0.15213', ' ; loss=', 0.06428)\n",
      "('Iter 11760: nmi = 0.38916, ari = 0.15410', ' ; loss=', 0.06217)\n",
      "('Iter 11900: nmi = 0.39409, ari = 0.15567', ' ; loss=', 0.06948)\n",
      "('Iter 12040: nmi = 0.39506, ari = 0.15572', ' ; loss=', 0.07649)\n",
      "('Iter 12180: nmi = 0.39481, ari = 0.15511', ' ; loss=', 0.08839)\n",
      "('Iter 12320: nmi = 0.39129, ari = 0.15410', ' ; loss=', 0.07551)\n",
      "('Iter 12460: nmi = 0.39185, ari = 0.15485', ' ; loss=', 0.05978)\n",
      "('Iter 12600: nmi = 0.39864, ari = 0.15769', ' ; loss=', 0.06789)\n",
      "('Iter 12740: nmi = 0.39752, ari = 0.15751', ' ; loss=', 0.0688)\n",
      "('Iter 12880: nmi = 0.39744, ari = 0.15797', ' ; loss=', 0.12332)\n",
      "('Iter 13020: nmi = 0.40334, ari = 0.16028', ' ; loss=', 0.07287)\n",
      "('Iter 13160: nmi = 0.40382, ari = 0.16070', ' ; loss=', 0.05453)\n",
      "('Iter 13300: nmi = 0.40514, ari = 0.16156', ' ; loss=', 0.05789)\n",
      "('Iter 13440: nmi = 0.40805, ari = 0.16288', ' ; loss=', 0.08072)\n",
      "('Iter 13580: nmi = 0.41001, ari = 0.16375', ' ; loss=', 0.11216)\n",
      "('Iter 13720: nmi = 0.41229, ari = 0.16415', ' ; loss=', 0.06139)\n",
      "('Iter 13860: nmi = 0.41185, ari = 0.16422', ' ; loss=', 0.05802)\n",
      "('Iter 14000: nmi = 0.41225, ari = 0.16426', ' ; loss=', 0.05185)\n",
      "('Iter 14140: nmi = 0.41230, ari = 0.16447', ' ; loss=', 0.04311)\n",
      "('Iter 14280: nmi = 0.41246, ari = 0.16458', ' ; loss=', 0.06814)\n",
      "('Iter 14420: nmi = 0.41565, ari = 0.16597', ' ; loss=', 0.12301)\n",
      "('Iter 14560: nmi = 0.41770, ari = 0.16704', ' ; loss=', 0.0804)\n",
      "('Iter 14700: nmi = 0.41945, ari = 0.16757', ' ; loss=', 0.0576)\n",
      "('Iter 14840: nmi = 0.41798, ari = 0.16706', ' ; loss=', 0.05453)\n",
      "('Iter 14980: nmi = 0.41820, ari = 0.16604', ' ; loss=', 0.07613)\n",
      "('Iter 15120: nmi = 0.41413, ari = 0.16280', ' ; loss=', 0.09053)\n",
      "('Iter 15260: nmi = 0.41164, ari = 0.16360', ' ; loss=', 0.05512)\n",
      "('Iter 15400: nmi = 0.40970, ari = 0.16332', ' ; loss=', 0.05362)\n",
      "('Iter 15540: nmi = 0.41226, ari = 0.16512', ' ; loss=', 0.05146)\n",
      "('Iter 15680: nmi = 0.41516, ari = 0.16625', ' ; loss=', 0.04771)\n",
      "('Iter 15820: nmi = 0.41839, ari = 0.16777', ' ; loss=', 0.06288)\n",
      "('Iter 15960: nmi = 0.42346, ari = 0.16983', ' ; loss=', 0.12435)\n"
     ]
    }
   ],
   "source": [
    "# computing an auxiliary target distribution\n",
    "def target_distribution(q):\n",
    "    weight = q ** 2 / q.sum(0)\n",
    "    return (weight.T / weight.sum(1)).T\n",
    "\n",
    "loss = 0\n",
    "index = 0\n",
    "maxiter = 16000\n",
    "update_interval = 140\n",
    "index_array = np.arange(x.shape[0])\n",
    "tol = 0.001 # tolerance threshold to stop training\n",
    "\n",
    "# start training\n",
    "\n",
    "for ite in range(int(maxiter)):\n",
    "    if ite % update_interval == 0:\n",
    "        q = model.predict(x, verbose=0)\n",
    "        p = target_distribution(q)  # update the auxiliary target distribution p\n",
    "\n",
    "        # evaluate the clustering performance\n",
    "        y_pred = q.argmax(1)\n",
    "        if y is not None:\n",
    "            nmi = np.round(metrics.mutual_info_score(y, y_pred), 5)\n",
    "            ari = np.round(metrics.adjusted_rand_score(y, y_pred), 5)\n",
    "            loss = np.round(loss, 5)\n",
    "            print('Iter %d: nmi = %.5f, ari = %.5f' % (ite, nmi, ari), ' ; loss=', loss)\n",
    "\n",
    "        # check stop criterion - model convergence\n",
    "        delta_label = np.sum(y_pred != y_pred_last).astype(np.float32) / y_pred.shape[0]\n",
    "        y_pred_last = np.copy(y_pred)\n",
    "        if ite > 0 and delta_label < tol:\n",
    "            print('delta_label ', delta_label, '< tol ', tol)\n",
    "            print('Reached tolerance threshold. Stopping training.')\n",
    "            break\n",
    "    idx = index_array[index * batch_size: min((index+1) * batch_size, x.shape[0])]\n",
    "    loss = model.train_on_batch(x=x[idx], y=p[idx])\n",
    "    index = index + 1 if (index + 1) * batch_size <= x.shape[0] else 0\n",
    "\n",
    "model.save_weights(save_dir + '/DEC_model_final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('nmi = 0.42028, ari = 0.16912', ' ; loss=', 0.06358)\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(save_dir + '/DEC_model_final.h5')\n",
    "# Eval.\n",
    "q = model.predict(x, verbose=0)\n",
    "p = target_distribution(q)  # update the auxiliary target distribution p\n",
    "\n",
    "# evaluate the clustering performance\n",
    "y_pred = q.argmax(1)\n",
    "if y is not None:\n",
    "    nmi = np.round(metrics.mutual_info_score(y, y_pred), 5)\n",
    "    ari = np.round(metrics.adjusted_rand_score(y, y_pred), 5)\n",
    "    loss = np.round(loss, 5)\n",
    "    print('nmi = %.5f, ari = %.5f' % (nmi, ari), ' ; loss=', loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2. Convolutional Auto-encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-794fa1e4f10f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# x = images.reshape(images.shape + (1,))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# images.shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'images' is not defined"
     ]
    }
   ],
   "source": [
    "# x = images.reshape(images.shape + (1,))\n",
    "# images.shape\n",
    "x = images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "5373/5373 [==============================] - 2s 371us/step - loss: 0.3638\n",
      "Epoch 2/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.1911\n",
      "Epoch 3/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.1778\n",
      "Epoch 4/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.1695\n",
      "Epoch 5/600\n",
      "5373/5373 [==============================] - 0s 37us/step - loss: 0.1644\n",
      "Epoch 6/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.1547\n",
      "Epoch 7/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.1522\n",
      "Epoch 8/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.1510\n",
      "Epoch 9/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.1430\n",
      "Epoch 10/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.1353\n",
      "Epoch 11/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.1330\n",
      "Epoch 12/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.1280\n",
      "Epoch 13/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.1266\n",
      "Epoch 14/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.1212\n",
      "Epoch 15/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.1175\n",
      "Epoch 16/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.1122\n",
      "Epoch 17/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.1100\n",
      "Epoch 18/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.1052\n",
      "Epoch 19/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.1015\n",
      "Epoch 20/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0991\n",
      "Epoch 21/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0964\n",
      "Epoch 22/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0945\n",
      "Epoch 23/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0919\n",
      "Epoch 24/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0908\n",
      "Epoch 25/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0892\n",
      "Epoch 26/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0876\n",
      "Epoch 27/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0848\n",
      "Epoch 28/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0845\n",
      "Epoch 29/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0835\n",
      "Epoch 30/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0824\n",
      "Epoch 31/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0813\n",
      "Epoch 32/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0799\n",
      "Epoch 33/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0793\n",
      "Epoch 34/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0780\n",
      "Epoch 35/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0771\n",
      "Epoch 36/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0769\n",
      "Epoch 37/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0767\n",
      "Epoch 38/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0751\n",
      "Epoch 39/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0747\n",
      "Epoch 40/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0739\n",
      "Epoch 41/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0729\n",
      "Epoch 42/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0732\n",
      "Epoch 43/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0722\n",
      "Epoch 44/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0721\n",
      "Epoch 45/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0713\n",
      "Epoch 46/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0708\n",
      "Epoch 47/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0709\n",
      "Epoch 48/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0703\n",
      "Epoch 49/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0701\n",
      "Epoch 50/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0684\n",
      "Epoch 51/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0692\n",
      "Epoch 52/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0682\n",
      "Epoch 53/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0683\n",
      "Epoch 54/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0681\n",
      "Epoch 55/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0672\n",
      "Epoch 56/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0676\n",
      "Epoch 57/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0664\n",
      "Epoch 58/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0666\n",
      "Epoch 59/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0659\n",
      "Epoch 60/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0666\n",
      "Epoch 61/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0654\n",
      "Epoch 62/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0650\n",
      "Epoch 63/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0651\n",
      "Epoch 64/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0648\n",
      "Epoch 65/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0643\n",
      "Epoch 66/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0645\n",
      "Epoch 67/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0637\n",
      "Epoch 68/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0636\n",
      "Epoch 69/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0632\n",
      "Epoch 70/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0635\n",
      "Epoch 71/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0629\n",
      "Epoch 72/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0629\n",
      "Epoch 73/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0622\n",
      "Epoch 74/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0620\n",
      "Epoch 75/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0627\n",
      "Epoch 76/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0624\n",
      "Epoch 77/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0618\n",
      "Epoch 78/600\n",
      "5373/5373 [==============================] - 0s 37us/step - loss: 0.0620\n",
      "Epoch 79/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0611\n",
      "Epoch 80/600\n",
      "5373/5373 [==============================] - 0s 37us/step - loss: 0.0612\n",
      "Epoch 81/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0614\n",
      "Epoch 82/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0606\n",
      "Epoch 83/600\n",
      "5373/5373 [==============================] - 0s 37us/step - loss: 0.0605\n",
      "Epoch 84/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0604\n",
      "Epoch 85/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0604\n",
      "Epoch 86/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0597\n",
      "Epoch 87/600\n",
      "5373/5373 [==============================] - 0s 37us/step - loss: 0.0599\n",
      "Epoch 88/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0599\n",
      "Epoch 89/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0597\n",
      "Epoch 90/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0591\n",
      "Epoch 91/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0592\n",
      "Epoch 92/600\n",
      "5373/5373 [==============================] - 0s 37us/step - loss: 0.0594\n",
      "Epoch 93/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0586\n",
      "Epoch 94/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0582\n",
      "Epoch 95/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0588\n",
      "Epoch 96/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0588\n",
      "Epoch 97/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0587\n",
      "Epoch 98/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0571\n",
      "Epoch 99/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0583\n",
      "Epoch 100/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0576\n",
      "Epoch 101/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0576\n",
      "Epoch 102/600\n",
      "5373/5373 [==============================] - 0s 41us/step - loss: 0.0571\n",
      "Epoch 103/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0575\n",
      "Epoch 104/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0571\n",
      "Epoch 105/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0565\n",
      "Epoch 106/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0567\n",
      "Epoch 107/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0568\n",
      "Epoch 108/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0567\n",
      "Epoch 109/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0560\n",
      "Epoch 110/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0556\n",
      "Epoch 111/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0562\n",
      "Epoch 112/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0557\n",
      "Epoch 113/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0559\n",
      "Epoch 114/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0558\n",
      "Epoch 115/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0555\n",
      "Epoch 116/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0556\n",
      "Epoch 117/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0553\n",
      "Epoch 118/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0550\n",
      "Epoch 119/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0552\n",
      "Epoch 120/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0551\n",
      "Epoch 121/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0550\n",
      "Epoch 122/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0538\n",
      "Epoch 123/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0552\n",
      "Epoch 124/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0541\n",
      "Epoch 125/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0546\n",
      "Epoch 126/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0539\n",
      "Epoch 127/600\n",
      "5373/5373 [==============================] - 0s 37us/step - loss: 0.0542\n",
      "Epoch 128/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0543\n",
      "Epoch 129/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0536\n",
      "Epoch 130/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0539\n",
      "Epoch 131/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0540\n",
      "Epoch 132/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0527\n",
      "Epoch 133/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0536\n",
      "Epoch 134/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0535\n",
      "Epoch 135/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0525\n",
      "Epoch 136/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0531\n",
      "Epoch 137/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0529\n",
      "Epoch 138/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0521\n",
      "Epoch 139/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0528\n",
      "Epoch 140/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0526\n",
      "Epoch 141/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0526\n",
      "Epoch 142/600\n",
      "5373/5373 [==============================] - 0s 41us/step - loss: 0.0525\n",
      "Epoch 143/600\n",
      "5373/5373 [==============================] - 0s 41us/step - loss: 0.0522\n",
      "Epoch 144/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0517\n",
      "Epoch 145/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0523\n",
      "Epoch 146/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0523\n",
      "Epoch 147/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0515\n",
      "Epoch 148/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0518\n",
      "Epoch 149/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0519\n",
      "Epoch 150/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0510\n",
      "Epoch 151/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0517\n",
      "Epoch 152/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0514\n",
      "Epoch 153/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0515\n",
      "Epoch 154/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0512\n",
      "Epoch 155/600\n",
      "5373/5373 [==============================] - 0s 41us/step - loss: 0.0511\n",
      "Epoch 156/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0515\n",
      "Epoch 157/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0512\n",
      "Epoch 158/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0512\n",
      "Epoch 159/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0505\n",
      "Epoch 160/600\n",
      "5373/5373 [==============================] - 0s 41us/step - loss: 0.0508\n",
      "Epoch 161/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0506\n",
      "Epoch 162/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0506\n",
      "Epoch 163/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0503\n",
      "Epoch 164/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0505\n",
      "Epoch 165/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0502\n",
      "Epoch 166/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0504\n",
      "Epoch 167/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0503\n",
      "Epoch 168/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0502\n",
      "Epoch 169/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0499\n",
      "Epoch 170/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0493\n",
      "Epoch 171/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0494\n",
      "Epoch 172/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0498\n",
      "Epoch 173/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0494\n",
      "Epoch 174/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0490\n",
      "Epoch 175/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0491\n",
      "Epoch 176/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0497\n",
      "Epoch 177/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0493\n",
      "Epoch 178/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0494\n",
      "Epoch 179/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0477\n",
      "Epoch 180/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0488\n",
      "Epoch 181/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0494\n",
      "Epoch 182/600\n",
      "5373/5373 [==============================] - 0s 41us/step - loss: 0.0485\n",
      "Epoch 183/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0490\n",
      "Epoch 184/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0485\n",
      "Epoch 185/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0485\n",
      "Epoch 186/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0483\n",
      "Epoch 187/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0485\n",
      "Epoch 188/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0487\n",
      "Epoch 189/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0482\n",
      "Epoch 190/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0484\n",
      "Epoch 191/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0482\n",
      "Epoch 192/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0485\n",
      "Epoch 193/600\n",
      "5373/5373 [==============================] - 0s 41us/step - loss: 0.0485\n",
      "Epoch 194/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0477\n",
      "Epoch 195/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0483\n",
      "Epoch 196/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0472\n",
      "Epoch 197/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0479\n",
      "Epoch 198/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0474\n",
      "Epoch 199/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0477\n",
      "Epoch 200/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0472\n",
      "Epoch 201/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0484\n",
      "Epoch 202/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0474\n",
      "Epoch 203/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0477\n",
      "Epoch 204/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0470\n",
      "Epoch 205/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0471\n",
      "Epoch 206/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0479\n",
      "Epoch 207/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0475\n",
      "Epoch 208/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0467\n",
      "Epoch 209/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0474\n",
      "Epoch 210/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0470\n",
      "Epoch 211/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0467\n",
      "Epoch 212/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0469\n",
      "Epoch 213/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0471\n",
      "Epoch 214/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0472\n",
      "Epoch 215/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0470\n",
      "Epoch 216/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0467\n",
      "Epoch 217/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0467\n",
      "Epoch 218/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0468\n",
      "Epoch 219/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0464\n",
      "Epoch 220/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0464\n",
      "Epoch 221/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0464\n",
      "Epoch 222/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0461\n",
      "Epoch 223/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0466\n",
      "Epoch 224/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0467\n",
      "Epoch 225/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0462\n",
      "Epoch 226/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0466\n",
      "Epoch 227/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0458\n",
      "Epoch 228/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0462\n",
      "Epoch 229/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0458\n",
      "Epoch 230/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0455\n",
      "Epoch 231/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0460\n",
      "Epoch 232/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0461\n",
      "Epoch 233/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0457\n",
      "Epoch 234/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0463\n",
      "Epoch 235/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0454\n",
      "Epoch 236/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0463\n",
      "Epoch 237/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0453\n",
      "Epoch 238/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0454\n",
      "Epoch 239/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0457\n",
      "Epoch 240/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0452\n",
      "Epoch 241/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0458\n",
      "Epoch 242/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0446\n",
      "Epoch 243/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0453\n",
      "Epoch 244/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0450\n",
      "Epoch 245/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0456\n",
      "Epoch 246/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0455\n",
      "Epoch 247/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0450\n",
      "Epoch 248/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0451\n",
      "Epoch 249/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0454\n",
      "Epoch 250/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0450\n",
      "Epoch 251/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0446\n",
      "Epoch 252/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0457\n",
      "Epoch 253/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0447\n",
      "Epoch 254/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0445\n",
      "Epoch 255/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0446\n",
      "Epoch 256/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0448\n",
      "Epoch 257/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0450\n",
      "Epoch 258/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0443\n",
      "Epoch 259/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0447\n",
      "Epoch 260/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0444\n",
      "Epoch 261/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0443\n",
      "Epoch 262/600\n",
      "5373/5373 [==============================] - 0s 37us/step - loss: 0.0445\n",
      "Epoch 263/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0441\n",
      "Epoch 264/600\n",
      "5373/5373 [==============================] - 0s 37us/step - loss: 0.0444\n",
      "Epoch 265/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0444\n",
      "Epoch 266/600\n",
      "5373/5373 [==============================] - 0s 37us/step - loss: 0.0446\n",
      "Epoch 267/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0442\n",
      "Epoch 268/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0444\n",
      "Epoch 269/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0442\n",
      "Epoch 270/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0449\n",
      "Epoch 271/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0438\n",
      "Epoch 272/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0440\n",
      "Epoch 273/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0439\n",
      "Epoch 274/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0440\n",
      "Epoch 275/600\n",
      "5373/5373 [==============================] - 0s 41us/step - loss: 0.0438\n",
      "Epoch 276/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0438\n",
      "Epoch 277/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0443\n",
      "Epoch 278/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0434\n",
      "Epoch 279/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0437\n",
      "Epoch 280/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0439\n",
      "Epoch 281/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0437\n",
      "Epoch 282/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0437\n",
      "Epoch 283/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0437\n",
      "Epoch 284/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0439\n",
      "Epoch 285/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0432\n",
      "Epoch 286/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0434\n",
      "Epoch 287/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0440\n",
      "Epoch 288/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0428\n",
      "Epoch 289/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0431\n",
      "Epoch 290/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0435\n",
      "Epoch 291/600\n",
      "5373/5373 [==============================] - 0s 41us/step - loss: 0.0433\n",
      "Epoch 292/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0434\n",
      "Epoch 293/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0435\n",
      "Epoch 294/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0432\n",
      "Epoch 295/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0429\n",
      "Epoch 296/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0430\n",
      "Epoch 297/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0430\n",
      "Epoch 298/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0430\n",
      "Epoch 299/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0432\n",
      "Epoch 300/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0427\n",
      "Epoch 301/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0429\n",
      "Epoch 302/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0436\n",
      "Epoch 303/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0424\n",
      "Epoch 304/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0421\n",
      "Epoch 305/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0427\n",
      "Epoch 306/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0423\n",
      "Epoch 307/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0426\n",
      "Epoch 308/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0430\n",
      "Epoch 309/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0426\n",
      "Epoch 310/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0426\n",
      "Epoch 311/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0434\n",
      "Epoch 312/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0421\n",
      "Epoch 313/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0422\n",
      "Epoch 314/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0429\n",
      "Epoch 315/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0423\n",
      "Epoch 316/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0426\n",
      "Epoch 317/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0424\n",
      "Epoch 318/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0426\n",
      "Epoch 319/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0426\n",
      "Epoch 320/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0421\n",
      "Epoch 321/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0424\n",
      "Epoch 322/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0419\n",
      "Epoch 323/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0422\n",
      "Epoch 324/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0414\n",
      "Epoch 325/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0426\n",
      "Epoch 326/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0423\n",
      "Epoch 327/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0416\n",
      "Epoch 328/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0417\n",
      "Epoch 329/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0420\n",
      "Epoch 330/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0419\n",
      "Epoch 331/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0422\n",
      "Epoch 332/600\n",
      "5373/5373 [==============================] - 0s 37us/step - loss: 0.0413\n",
      "Epoch 333/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0419\n",
      "Epoch 334/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0416\n",
      "Epoch 335/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0423\n",
      "Epoch 336/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0416\n",
      "Epoch 337/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0415\n",
      "Epoch 338/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0411\n",
      "Epoch 339/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0420\n",
      "Epoch 340/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0413\n",
      "Epoch 341/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0416\n",
      "Epoch 342/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0420\n",
      "Epoch 343/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0410\n",
      "Epoch 344/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0413\n",
      "Epoch 345/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0414\n",
      "Epoch 346/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0417\n",
      "Epoch 347/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0411\n",
      "Epoch 348/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0416\n",
      "Epoch 349/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0415\n",
      "Epoch 350/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0413\n",
      "Epoch 351/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0417\n",
      "Epoch 352/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0416\n",
      "Epoch 353/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0405\n",
      "Epoch 354/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0407\n",
      "Epoch 355/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0414\n",
      "Epoch 356/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0415\n",
      "Epoch 357/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0408\n",
      "Epoch 358/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0409\n",
      "Epoch 359/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0410\n",
      "Epoch 360/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0415\n",
      "Epoch 361/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0408\n",
      "Epoch 362/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0411\n",
      "Epoch 363/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0408\n",
      "Epoch 364/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0408\n",
      "Epoch 365/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0404\n",
      "Epoch 366/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0408\n",
      "Epoch 367/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0410\n",
      "Epoch 368/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0408\n",
      "Epoch 369/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0406\n",
      "Epoch 370/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0409\n",
      "Epoch 371/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0407\n",
      "Epoch 372/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0403\n",
      "Epoch 373/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0403\n",
      "Epoch 374/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0411\n",
      "Epoch 375/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0406\n",
      "Epoch 376/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0402\n",
      "Epoch 377/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0404\n",
      "Epoch 378/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0409\n",
      "Epoch 379/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0404\n",
      "Epoch 380/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0403\n",
      "Epoch 381/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0410\n",
      "Epoch 382/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0409\n",
      "Epoch 383/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0396\n",
      "Epoch 384/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0401\n",
      "Epoch 385/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0400\n",
      "Epoch 386/600\n",
      "5373/5373 [==============================] - 0s 37us/step - loss: 0.0401\n",
      "Epoch 387/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0407\n",
      "Epoch 388/600\n",
      "5373/5373 [==============================] - 0s 37us/step - loss: 0.0402\n",
      "Epoch 389/600\n",
      "5373/5373 [==============================] - 0s 37us/step - loss: 0.0400\n",
      "Epoch 390/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0405\n",
      "Epoch 391/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0392\n",
      "Epoch 392/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0403\n",
      "Epoch 393/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0396\n",
      "Epoch 394/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0392\n",
      "Epoch 395/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0394\n",
      "Epoch 396/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0399\n",
      "Epoch 397/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0398\n",
      "Epoch 398/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0390\n",
      "Epoch 399/600\n",
      "5373/5373 [==============================] - 0s 37us/step - loss: 0.0399\n",
      "Epoch 400/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0400\n",
      "Epoch 401/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0393\n",
      "Epoch 402/600\n",
      "5373/5373 [==============================] - 0s 37us/step - loss: 0.0398\n",
      "Epoch 403/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0396\n",
      "Epoch 404/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0397\n",
      "Epoch 405/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0397\n",
      "Epoch 406/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0396\n",
      "Epoch 407/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0395\n",
      "Epoch 408/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0394\n",
      "Epoch 409/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0398\n",
      "Epoch 410/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0400\n",
      "Epoch 411/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0394\n",
      "Epoch 412/600\n",
      "5373/5373 [==============================] - 0s 37us/step - loss: 0.0396\n",
      "Epoch 413/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0396\n",
      "Epoch 414/600\n",
      "5373/5373 [==============================] - 0s 37us/step - loss: 0.0397\n",
      "Epoch 415/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0394\n",
      "Epoch 416/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0396\n",
      "Epoch 417/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0394\n",
      "Epoch 418/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0396\n",
      "Epoch 419/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0398\n",
      "Epoch 420/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0394\n",
      "Epoch 421/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0395\n",
      "Epoch 422/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0391\n",
      "Epoch 423/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0393\n",
      "Epoch 424/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0393\n",
      "Epoch 425/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0390\n",
      "Epoch 426/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0397\n",
      "Epoch 427/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0395\n",
      "Epoch 428/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0391\n",
      "Epoch 429/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0394\n",
      "Epoch 430/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0396\n",
      "Epoch 431/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0393\n",
      "Epoch 432/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0395\n",
      "Epoch 433/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0389\n",
      "Epoch 434/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0390\n",
      "Epoch 435/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0386\n",
      "Epoch 436/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0387\n",
      "Epoch 437/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0392\n",
      "Epoch 438/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0392\n",
      "Epoch 439/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0389\n",
      "Epoch 440/600\n",
      "5373/5373 [==============================] - 0s 37us/step - loss: 0.0389\n",
      "Epoch 441/600\n",
      "5373/5373 [==============================] - 0s 37us/step - loss: 0.0382\n",
      "Epoch 442/600\n",
      "5373/5373 [==============================] - 0s 37us/step - loss: 0.0389\n",
      "Epoch 443/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0389\n",
      "Epoch 444/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0387\n",
      "Epoch 445/600\n",
      "5373/5373 [==============================] - 0s 37us/step - loss: 0.0387\n",
      "Epoch 446/600\n",
      "5373/5373 [==============================] - 0s 37us/step - loss: 0.0389\n",
      "Epoch 447/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0389\n",
      "Epoch 448/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0386\n",
      "Epoch 449/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0385\n",
      "Epoch 450/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0390\n",
      "Epoch 451/600\n",
      "5373/5373 [==============================] - 0s 37us/step - loss: 0.0387\n",
      "Epoch 452/600\n",
      "5373/5373 [==============================] - 0s 37us/step - loss: 0.0384\n",
      "Epoch 453/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0390\n",
      "Epoch 454/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0392\n",
      "Epoch 455/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0389\n",
      "Epoch 456/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0385\n",
      "Epoch 457/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0382\n",
      "Epoch 458/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0390\n",
      "Epoch 459/600\n",
      "5373/5373 [==============================] - 0s 37us/step - loss: 0.0387\n",
      "Epoch 460/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0381\n",
      "Epoch 461/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0385\n",
      "Epoch 462/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0385\n",
      "Epoch 463/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0384\n",
      "Epoch 464/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0386\n",
      "Epoch 465/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0379\n",
      "Epoch 466/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0384\n",
      "Epoch 467/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0387\n",
      "Epoch 468/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0375\n",
      "Epoch 469/600\n",
      "5373/5373 [==============================] - 0s 37us/step - loss: 0.0381\n",
      "Epoch 470/600\n",
      "5373/5373 [==============================] - 0s 37us/step - loss: 0.0374\n",
      "Epoch 471/600\n",
      "5373/5373 [==============================] - 0s 36us/step - loss: 0.0382\n",
      "Epoch 472/600\n",
      "5373/5373 [==============================] - 0s 36us/step - loss: 0.0389\n",
      "Epoch 473/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0381\n",
      "Epoch 474/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0379\n",
      "Epoch 475/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0379\n",
      "Epoch 476/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0383\n",
      "Epoch 477/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0381\n",
      "Epoch 478/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0380\n",
      "Epoch 479/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0372\n",
      "Epoch 480/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0373\n",
      "Epoch 481/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0379\n",
      "Epoch 482/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0378\n",
      "Epoch 483/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0378\n",
      "Epoch 484/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0377\n",
      "Epoch 485/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0377\n",
      "Epoch 486/600\n",
      "5373/5373 [==============================] - 0s 36us/step - loss: 0.0381\n",
      "Epoch 487/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0380\n",
      "Epoch 488/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0380\n",
      "Epoch 489/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0375\n",
      "Epoch 490/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0376\n",
      "Epoch 491/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0380\n",
      "Epoch 492/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0375\n",
      "Epoch 493/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0374\n",
      "Epoch 494/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0379\n",
      "Epoch 495/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0375\n",
      "Epoch 496/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0376\n",
      "Epoch 497/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0378\n",
      "Epoch 498/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0377\n",
      "Epoch 499/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0379\n",
      "Epoch 500/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0377\n",
      "Epoch 501/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0372\n",
      "Epoch 502/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0375\n",
      "Epoch 503/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0379\n",
      "Epoch 504/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0373\n",
      "Epoch 505/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0378\n",
      "Epoch 506/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0371\n",
      "Epoch 507/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0368\n",
      "Epoch 508/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0373\n",
      "Epoch 509/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0377\n",
      "Epoch 510/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0378\n",
      "Epoch 511/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0372\n",
      "Epoch 512/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0375\n",
      "Epoch 513/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0372\n",
      "Epoch 514/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0374\n",
      "Epoch 515/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0376\n",
      "Epoch 516/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0369\n",
      "Epoch 517/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0376\n",
      "Epoch 518/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0372\n",
      "Epoch 519/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0372\n",
      "Epoch 520/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0368\n",
      "Epoch 521/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0375\n",
      "Epoch 522/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0371\n",
      "Epoch 523/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0374\n",
      "Epoch 524/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0370\n",
      "Epoch 525/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0376\n",
      "Epoch 526/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0370\n",
      "Epoch 527/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0373\n",
      "Epoch 528/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0375\n",
      "Epoch 529/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0367\n",
      "Epoch 530/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0371\n",
      "Epoch 531/600\n",
      "5373/5373 [==============================] - 0s 37us/step - loss: 0.0367\n",
      "Epoch 532/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0367\n",
      "Epoch 533/600\n",
      "5373/5373 [==============================] - 0s 41us/step - loss: 0.0367\n",
      "Epoch 534/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0368\n",
      "Epoch 535/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0370\n",
      "Epoch 536/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0367\n",
      "Epoch 537/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0366\n",
      "Epoch 538/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0368\n",
      "Epoch 539/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0368\n",
      "Epoch 540/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0370\n",
      "Epoch 541/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0372\n",
      "Epoch 542/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0368\n",
      "Epoch 543/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0363\n",
      "Epoch 544/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0368\n",
      "Epoch 545/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0368\n",
      "Epoch 546/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0371\n",
      "Epoch 547/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0372\n",
      "Epoch 548/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0365\n",
      "Epoch 549/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0368\n",
      "Epoch 550/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0371\n",
      "Epoch 551/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0372\n",
      "Epoch 552/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0367\n",
      "Epoch 553/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0366\n",
      "Epoch 554/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0363\n",
      "Epoch 555/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0371\n",
      "Epoch 556/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0368\n",
      "Epoch 557/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0359\n",
      "Epoch 558/600\n",
      "5373/5373 [==============================] - 0s 41us/step - loss: 0.0361\n",
      "Epoch 559/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0363\n",
      "Epoch 560/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0364\n",
      "Epoch 561/600\n",
      "5373/5373 [==============================] - 0s 41us/step - loss: 0.0367\n",
      "Epoch 562/600\n",
      "5373/5373 [==============================] - 0s 41us/step - loss: 0.0367\n",
      "Epoch 563/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0367\n",
      "Epoch 564/600\n",
      "5373/5373 [==============================] - 0s 41us/step - loss: 0.0369\n",
      "Epoch 565/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0365\n",
      "Epoch 566/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0360\n",
      "Epoch 567/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0360\n",
      "Epoch 568/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0364\n",
      "Epoch 569/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0363\n",
      "Epoch 570/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0361\n",
      "Epoch 571/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0363\n",
      "Epoch 572/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0360\n",
      "Epoch 573/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0363\n",
      "Epoch 574/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0364\n",
      "Epoch 575/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0360\n",
      "Epoch 576/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0364\n",
      "Epoch 577/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0363\n",
      "Epoch 578/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0361\n",
      "Epoch 579/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0362\n",
      "Epoch 580/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0365\n",
      "Epoch 581/600\n",
      "5373/5373 [==============================] - 0s 41us/step - loss: 0.0368\n",
      "Epoch 582/600\n",
      "5373/5373 [==============================] - 0s 37us/step - loss: 0.0356\n",
      "Epoch 583/600\n",
      "5373/5373 [==============================] - 0s 37us/step - loss: 0.0357\n",
      "Epoch 584/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0362\n",
      "Epoch 585/600\n",
      "5373/5373 [==============================] - 0s 37us/step - loss: 0.0361\n",
      "Epoch 586/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0362\n",
      "Epoch 587/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0360\n",
      "Epoch 588/600\n",
      "5373/5373 [==============================] - 0s 38us/step - loss: 0.0357\n",
      "Epoch 589/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0366\n",
      "Epoch 590/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0356\n",
      "Epoch 591/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0358\n",
      "Epoch 592/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0358\n",
      "Epoch 593/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0354\n",
      "Epoch 594/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0355\n",
      "Epoch 595/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0357\n",
      "Epoch 596/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0360\n",
      "Epoch 597/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0360\n",
      "Epoch 598/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0361\n",
      "Epoch 599/600\n",
      "5373/5373 [==============================] - 0s 39us/step - loss: 0.0360\n",
      "Epoch 600/600\n",
      "5373/5373 [==============================] - 0s 40us/step - loss: 0.0360\n"
     ]
    }
   ],
   "source": [
    "def autoencoderConv2D_1(input_shape=(28, 28, 1), filters=[32, 64, 128, 10]):\n",
    "    input_img = Input(shape=input_shape)\n",
    "    if input_shape[0] % 8 == 0:\n",
    "        pad3 = 'same'\n",
    "    else:\n",
    "        pad3 = 'valid'\n",
    "    x = Conv2D(filters[0], 5, strides=2, padding='same', activation='relu', name='conv1', input_shape=input_shape)(input_img)\n",
    "\n",
    "    x = Conv2D(filters[1], 5, strides=2, padding='same', activation='relu', name='conv2')(x)\n",
    "\n",
    "    x = Conv2D(filters[2], 3, strides=2, padding=pad3, activation='relu', name='conv3')(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    encoded = Dense(units=filters[3], name='embedding')(x)\n",
    "    x = Dense(units=filters[2]*int(input_shape[0]/8)*int(input_shape[0]/8), activation='relu')(encoded)\n",
    "\n",
    "    x = Reshape((int(input_shape[0]/8), int(input_shape[0]/8), filters[2]))(x)\n",
    "    x = Conv2DTranspose(filters[1], 3, strides=2, padding=pad3, activation='relu', name='deconv3')(x)\n",
    "\n",
    "    x = Conv2DTranspose(filters[0], 5, strides=2, padding='same', activation='relu', name='deconv2')(x)\n",
    "\n",
    "    decoded = Conv2DTranspose(input_shape[2], 5, strides=2, padding='same', name='deconv1')(x)\n",
    "    return Model(inputs=input_img, outputs=decoded, name='AE'), Model(inputs=input_img, outputs=encoded, name='encoder')\n",
    "\n",
    "autoencoder2, encoder2 = autoencoderConv2D_1(input_shape=(28, 28, 1), filters=[32, 64, 128, 10])\n",
    "pretrain_epochs = 600\n",
    "batch_size = 200\n",
    "autoencoder2.compile(optimizer='adadelta', loss='mse')\n",
    "autoencoder2.fit(x, x, batch_size=batch_size, epochs=pretrain_epochs)\n",
    "autoencoder2.save_weights(save_dir+'/conv_ae_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6639839888491164\n",
      "Convolutional Auto-encoder 1 has ARI: 0.285273\n"
     ]
    }
   ],
   "source": [
    "autoencoder2.load_weights(save_dir+'/conv_ae_weights.h5')\n",
    "clustering_layer = ClusteringLayer(n_clusters, name='clustering')(encoder2.output)\n",
    "model = Model(inputs=encoder2.input, outputs=clustering_layer)\n",
    "model.compile(optimizer='adam', loss='kld')\n",
    "\n",
    "kmeans = KMeans(n_clusters=n_clusters, n_init=20)\n",
    "y_pred = kmeans.fit_predict(encoder2.predict(x))\n",
    "y_pred_last = np.copy(y_pred)\n",
    "print(metrics.mutual_info_score(y, y_pred_last))\n",
    "print ('Convolutional Auto-encoder 1 has ARI: %f' % metrics.adjusted_rand_score(y,y_pred_last))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iter 0:nmi = 0.66398, ari = 0.28527', ' ; loss=', 0)\n",
      "('Iter 300:nmi = 0.66582, ari = 0.28591', ' ; loss=', 0.01879)\n",
      "('Iter 600:nmi = 0.66122, ari = 0.28732', ' ; loss=', 0.0374)\n",
      "('Iter 900:nmi = 0.70110, ari = 0.30428', ' ; loss=', 0.10123)\n",
      "('Iter 1200:nmi = 0.68438, ari = 0.30360', ' ; loss=', 0.0846)\n",
      "('Iter 1500:nmi = 0.69733, ari = 0.31076', ' ; loss=', 0.04388)\n",
      "('Iter 1800:nmi = 0.70787, ari = 0.31437', ' ; loss=', 0.32311)\n",
      "('Iter 2100:nmi = 0.70670, ari = 0.31565', ' ; loss=', 0.06742)\n",
      "('Iter 2400:nmi = 0.71533, ari = 0.31918', ' ; loss=', 0.06896)\n",
      "('Iter 2700:nmi = 0.71504, ari = 0.31905', ' ; loss=', 0.06837)\n",
      "('Iter 3000:nmi = 0.71781, ari = 0.32043', ' ; loss=', 0.04501)\n",
      "('Iter 3300:nmi = 0.72123, ari = 0.32291', ' ; loss=', 0.04325)\n",
      "('Iter 3600:nmi = 0.72278, ari = 0.32230', ' ; loss=', 0.03168)\n",
      "('Iter 3900:nmi = 0.72290, ari = 0.32203', ' ; loss=', 0.0352)\n",
      "('Iter 4200:nmi = 0.72160, ari = 0.32174', ' ; loss=', 0.02838)\n",
      "('Iter 4500:nmi = 0.72139, ari = 0.32217', ' ; loss=', 0.16526)\n",
      "('delta_label ', 0.000744463056020845, '< tol ', 0.001)\n",
      "Reached tolerance threshold. Stopping training.\n",
      "('nmi = 0.72139, ari = 0.32217', ' ; loss=', 0.16526)\n"
     ]
    }
   ],
   "source": [
    "model.get_layer(name='clustering').set_weights([kmeans.cluster_centers_])\n",
    "loss = 0\n",
    "index = 0\n",
    "maxiter = 16000\n",
    "update_interval = 300\n",
    "index_array = np.arange(x.shape[0])\n",
    "tol = 0.001 # tolerance threshold to stop training\n",
    "\n",
    "# start training\n",
    "for ite in range(int(maxiter)):\n",
    "    if ite % update_interval == 0:\n",
    "        q = model.predict(x, verbose=0)\n",
    "        p = target_distribution(q)  # update the auxiliary target distribution p\n",
    "\n",
    "        # evaluate the clustering performance\n",
    "        y_pred = q.argmax(1)\n",
    "        if y is not None:\n",
    "            nmi = np.round(metrics.mutual_info_score(y, y_pred), 5)\n",
    "            ari = np.round(metrics.adjusted_rand_score(y, y_pred), 5)\n",
    "            loss = np.round(loss, 5)\n",
    "            print('Iter %d:nmi = %.5f, ari = %.5f' % (ite,nmi, ari), ' ; loss=', loss)\n",
    "\n",
    "        # check stop criterion\n",
    "        delta_label = np.sum(y_pred != y_pred_last).astype(np.float32) / y_pred.shape[0]\n",
    "        y_pred_last = np.copy(y_pred)\n",
    "        if ite > 0 and delta_label < tol:\n",
    "            print('delta_label ', delta_label, '< tol ', tol)\n",
    "            print('Reached tolerance threshold. Stopping training.')\n",
    "            break\n",
    "    idx = index_array[index * batch_size: min((index+1) * batch_size, x.shape[0])]\n",
    "    loss = model.train_on_batch(x=x[idx], y=p[idx])\n",
    "    index = index + 1 if (index + 1) * batch_size <= x.shape[0] else 0\n",
    "\n",
    "model.save_weights(save_dir + '/conv_DEC_model_final.h5')\n",
    "\n",
    "#Load the clustering model trained weights\n",
    "model.load_weights(save_dir + '/conv_DEC_model_final.h5')\n",
    "# Eval.\n",
    "q = model.predict(x, verbose=0)\n",
    "p = target_distribution(q)  # update the auxiliary target distribution p\n",
    "\n",
    "# evaluate the clustering performance\n",
    "y_pred = q.argmax(1)\n",
    "if y is not None:\n",
    "    nmi = np.round(metrics.mutual_info_score(y, y_pred), 5)\n",
    "    ari = np.round(metrics.adjusted_rand_score(y, y_pred), 5)\n",
    "    loss = np.round(loss, 5)\n",
    "    print('nmi = %.5f, ari = %.5f' % (nmi, ari), ' ; loss=', loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000744463056020845"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3. Model to train Autoencoder and clustering layer together (Conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder, encoder = autoencoderConv2D_1()\n",
    "autoencoder.load_weights(save_dir+'/conv_ae_weights.h5')\n",
    "clustering_layer = ClusteringLayer(n_clusters, name='clustering')(encoder.output)\n",
    "model = Model(inputs=encoder.input, outputs=[clustering_layer, autoencoder.output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=n_clusters, n_init=20)\n",
    "y_pred = kmeans.fit_predict(encoder.predict(x))\n",
    "model.get_layer(name='clustering').set_weights([kmeans.cluster_centers_])\n",
    "y_pred_last = np.copy(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iter 0:nmi = 0.66376, ari = 0.28183', ' ; loss=', 0)\n",
      "('Iter 300:nmi = 0.65132, ari = 0.25941', ' ; loss=', array([0.03009, 0.02939, 0.02715], dtype=float32))\n",
      "('Iter 600:nmi = 0.66912, ari = 0.26629', ' ; loss=', array([0.04996, 0.06818, 0.04314], dtype=float32))\n",
      "('Iter 900:nmi = 0.67831, ari = 0.27690', ' ; loss=', array([0.07052, 0.10286, 0.06024], dtype=float32))\n",
      "('Iter 1200:nmi = 0.68289, ari = 0.28785', ' ; loss=', array([0.06975, 0.10839, 0.05891], dtype=float32))\n",
      "('Iter 1500:nmi = 0.68355, ari = 0.29493', ' ; loss=', array([0.06498, 0.12008, 0.05298], dtype=float32))\n",
      "('Iter 1800:nmi = 0.69049, ari = 0.29709', ' ; loss=', array([0.0536 , 0.18909, 0.03469], dtype=float32))\n",
      "('Iter 2100:nmi = 0.69186, ari = 0.29980', ' ; loss=', array([0.07475, 0.11607, 0.06314], dtype=float32))\n",
      "('Iter 2400:nmi = 0.69788, ari = 0.30148', ' ; loss=', array([0.08713, 0.12205, 0.07493], dtype=float32))\n",
      "('Iter 2700:nmi = 0.70306, ari = 0.30257', ' ; loss=', array([0.03493, 0.11506, 0.02342], dtype=float32))\n",
      "('Iter 3000:nmi = 0.71934, ari = 0.31057', ' ; loss=', array([0.03574, 0.08258, 0.02749], dtype=float32))\n",
      "('Iter 3300:nmi = 0.72144, ari = 0.31237', ' ; loss=', array([0.04654, 0.08925, 0.03762], dtype=float32))\n",
      "('Iter 3600:nmi = 0.72979, ari = 0.31285', ' ; loss=', array([0.06643, 0.08555, 0.05788], dtype=float32))\n",
      "('Iter 3900:nmi = 0.72455, ari = 0.30815', ' ; loss=', array([0.06156, 0.10281, 0.05128], dtype=float32))\n",
      "('Iter 4200:nmi = 0.73074, ari = 0.31203', ' ; loss=', array([0.05558, 0.09388, 0.04619], dtype=float32))\n",
      "('Iter 4500:nmi = 0.73378, ari = 0.31481', ' ; loss=', array([0.05596, 0.16214, 0.03975], dtype=float32))\n",
      "('Iter 4800:nmi = 0.73175, ari = 0.31364', ' ; loss=', array([0.06642, 0.08732, 0.05769], dtype=float32))\n",
      "('Iter 5100:nmi = 0.73606, ari = 0.31740', ' ; loss=', array([0.07897, 0.10359, 0.06861], dtype=float32))\n",
      "('Iter 5400:nmi = 0.73879, ari = 0.31854', ' ; loss=', array([0.02576, 0.07006, 0.01875], dtype=float32))\n",
      "('Iter 5700:nmi = 0.73683, ari = 0.31730', ' ; loss=', array([0.03077, 0.05521, 0.02524], dtype=float32))\n",
      "('Iter 6000:nmi = 0.74081, ari = 0.31995', ' ; loss=', array([0.04309, 0.07518, 0.03557], dtype=float32))\n",
      "('Iter 6300:nmi = 0.73846, ari = 0.31879', ' ; loss=', array([0.06078, 0.07097, 0.05369], dtype=float32))\n",
      "('Iter 6600:nmi = 0.73917, ari = 0.31927', ' ; loss=', array([0.05298, 0.07914, 0.04507], dtype=float32))\n",
      "('Iter 6900:nmi = 0.73337, ari = 0.31765', ' ; loss=', array([0.0555 , 0.1049 , 0.04501], dtype=float32))\n",
      "('Iter 7200:nmi = 0.73471, ari = 0.31805', ' ; loss=', array([0.03804, 0.09194, 0.02884], dtype=float32))\n",
      "('Iter 7500:nmi = 0.73064, ari = 0.31648', ' ; loss=', array([0.06024, 0.09433, 0.0508 ], dtype=float32))\n",
      "('Iter 7800:nmi = 0.73229, ari = 0.31707', ' ; loss=', array([0.06903, 0.08029, 0.061  ], dtype=float32))\n",
      "('Iter 8100:nmi = 0.73558, ari = 0.31864', ' ; loss=', array([0.02282, 0.06119, 0.0167 ], dtype=float32))\n",
      "('Iter 8400:nmi = 0.73556, ari = 0.31884', ' ; loss=', array([0.02881, 0.05837, 0.02297], dtype=float32))\n",
      "('Iter 8700:nmi = 0.73940, ari = 0.31894', ' ; loss=', array([0.03877, 0.06698, 0.03207], dtype=float32))\n",
      "('Iter 9000:nmi = 0.74006, ari = 0.31941', ' ; loss=', array([0.05582, 0.08461, 0.04736], dtype=float32))\n",
      "('Iter 9300:nmi = 0.74330, ari = 0.32076', ' ; loss=', array([0.04636, 0.06097, 0.04026], dtype=float32))\n",
      "('Iter 9600:nmi = 0.74288, ari = 0.32025', ' ; loss=', array([0.04408, 0.07115, 0.03696], dtype=float32))\n",
      "('Iter 9900:nmi = 0.74231, ari = 0.32079', ' ; loss=', array([0.03216, 0.07648, 0.02451], dtype=float32))\n",
      "('Iter 10200:nmi = 0.74351, ari = 0.32071', ' ; loss=', array([0.05311, 0.07638, 0.04547], dtype=float32))\n",
      "('Iter 10500:nmi = 0.74518, ari = 0.32155', ' ; loss=', array([0.06661, 0.08029, 0.05859], dtype=float32))\n",
      "('Iter 10800:nmi = 0.74441, ari = 0.32106', ' ; loss=', array([0.02071, 0.05659, 0.01505], dtype=float32))\n",
      "('Iter 11100:nmi = 0.74230, ari = 0.32054', ' ; loss=', array([0.02567, 0.04046, 0.02162], dtype=float32))\n",
      "('Iter 11400:nmi = 0.74233, ari = 0.32096', ' ; loss=', array([0.03756, 0.06217, 0.03135], dtype=float32))\n",
      "('Iter 11700:nmi = 0.74102, ari = 0.32031', ' ; loss=', array([0.05189, 0.06323, 0.04557], dtype=float32))\n",
      "('Iter 12000:nmi = 0.74213, ari = 0.32059', ' ; loss=', array([0.04461, 0.06167, 0.03844], dtype=float32))\n",
      "('delta_label ', 0.0009305788200260562, '< tol ', 0.001)\n",
      "Reached tolerance threshold. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loss = 0\n",
    "index = 0\n",
    "maxiter = 16000\n",
    "update_interval = 300\n",
    "index_array = np.arange(x.shape[0])\n",
    "tol = 0.001 # tolerance threshold to stop training\n",
    "model.compile(loss=['kld', 'mse'], loss_weights=[0.1, 1], optimizer='adam')\n",
    "# start training\n",
    "for ite in range(int(maxiter)):\n",
    "    if ite % update_interval == 0:\n",
    "        q, _  = model.predict(x, verbose=0)\n",
    "        p = target_distribution(q)  # update the auxiliary target distribution p\n",
    "\n",
    "        # evaluate the clustering performance\n",
    "        y_pred = q.argmax(1)\n",
    "        if y is not None:\n",
    "            nmi = np.round(metrics.mutual_info_score(y, y_pred), 5)\n",
    "            ari = np.round(metrics.adjusted_rand_score(y, y_pred), 5)\n",
    "            loss = np.round(loss, 5)\n",
    "            print('Iter %d:nmi = %.5f, ari = %.5f' % (ite,nmi, ari), ' ; loss=', loss)\n",
    "\n",
    "        # check stop criterion\n",
    "        delta_label = np.sum(y_pred != y_pred_last).astype(np.float32) / y_pred.shape[0]\n",
    "        y_pred_last = np.copy(y_pred)\n",
    "        if ite > 0 and delta_label < tol:\n",
    "            print('delta_label ', delta_label, '< tol ', tol)\n",
    "            print('Reached tolerance threshold. Stopping training.')\n",
    "            break\n",
    "    idx = index_array[index * batch_size: min((index+1) * batch_size, x.shape[0])]\n",
    "    loss = model.train_on_batch(x=x[idx], y=[p[idx], x[idx]])\n",
    "    index = index + 1 if (index + 1) * batch_size <= x.shape[0] else 0\n",
    "\n",
    "model.save_weights(save_dir + '/conv_b_DEC_model_final.h5')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('nmi = 0.74213, ari = 0.32059', ' ; loss=', array([0.04461, 0.06167, 0.03844], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(save_dir + '/conv_b_DEC_model_final.h5')\n",
    "\n",
    "q, _ = model.predict(x, verbose=0)\n",
    "p = target_distribution(q)  # update the auxiliary target distribution p\n",
    "\n",
    "# evaluate the clustering performance\n",
    "y_pred = q.argmax(1)\n",
    "if y is not None:\n",
    "    nmi = np.round(metrics.mutual_info_score(y, y_pred), 5)\n",
    "    ari = np.round(metrics.adjusted_rand_score(y, y_pred), 5)\n",
    "    loss = np.round(loss, 5)\n",
    "    print('nmi = %.5f, ari = %.5f' % (nmi, ari), ' ; loss=', loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 4. Model to train Autoencoder and clustering layer together (Fully connected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5373, 784)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = images.reshape((images.shape[0], -1))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = [x.shape[-1], 500, 500, 2000, 10]\n",
    "init = VarianceScaling(scale=1. / 3., mode='fan_in',\n",
    "                           distribution='uniform')\n",
    "pretrain_optimizer = SGD(lr=0.01, momentum=0.9)\n",
    "pretrain_epochs = 600\n",
    "batch_size = 200\n",
    "save_dir = './results'\n",
    "\n",
    "\n",
    "from encoder_function import autoencoder\n",
    "autoencoder, encoder = autoencoder(dims, init=init)\n",
    "autoencoder.load_weights(save_dir+'/ae_weights.h5')\n",
    "clustering_layer = ClusteringLayer(n_clusters, name='clustering')(encoder.output)\n",
    "model = Model(inputs=encoder.input,\n",
    "            outputs=[clustering_layer, autoencoder.output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=n_clusters, n_init=20)\n",
    "y_pred = kmeans.fit_predict(encoder.predict(x))\n",
    "model.get_layer(name='clustering').set_weights([kmeans.cluster_centers_])\n",
    "y_pred_last = np.copy(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iter 0:nmi = 0.28587, ari = 0.09329', ' ; loss=', array([0.04461, 0.06167, 0.03844], dtype=float32))\n",
      "('Iter 300:nmi = 0.30203, ari = 0.09620', ' ; loss=', array([0.12691, 0.08436, 0.11847], dtype=float32))\n",
      "('Iter 600:nmi = 0.30663, ari = 0.09980', ' ; loss=', array([0.10021, 0.13862, 0.08635], dtype=float32))\n",
      "('Iter 900:nmi = 0.31579, ari = 0.10498', ' ; loss=', array([0.126  , 0.14096, 0.1119 ], dtype=float32))\n",
      "('Iter 1200:nmi = 0.32852, ari = 0.10898', ' ; loss=', array([0.14516, 0.15443, 0.12972], dtype=float32))\n",
      "('Iter 1500:nmi = 0.33639, ari = 0.11142', ' ; loss=', array([0.05179, 0.14722, 0.03706], dtype=float32))\n",
      "('Iter 1800:nmi = 0.34449, ari = 0.11414', ' ; loss=', array([0.05478, 0.13686, 0.04109], dtype=float32))\n",
      "('Iter 2100:nmi = 0.35333, ari = 0.11830', ' ; loss=', array([0.09267, 0.15346, 0.07732], dtype=float32))\n",
      "('Iter 2400:nmi = 0.35540, ari = 0.12115', ' ; loss=', array([0.10023, 0.14199, 0.08603], dtype=float32))\n",
      "('Iter 2700:nmi = 0.35148, ari = 0.11965', ' ; loss=', array([0.10617, 0.13338, 0.09284], dtype=float32))\n",
      "('Iter 3000:nmi = 0.35237, ari = 0.11955', ' ; loss=', array([0.09929, 0.12999, 0.08629], dtype=float32))\n",
      "('Iter 3300:nmi = 0.35421, ari = 0.12020', ' ; loss=', array([0.08146, 0.16976, 0.06448], dtype=float32))\n",
      "('Iter 3600:nmi = 0.35821, ari = 0.12168', ' ; loss=', array([0.10659, 0.15807, 0.09079], dtype=float32))\n",
      "('Iter 3900:nmi = 0.35903, ari = 0.12115', ' ; loss=', array([0.13086, 0.1764 , 0.11322], dtype=float32))\n",
      "('Iter 4200:nmi = 0.35996, ari = 0.12169', ' ; loss=', array([0.04526, 0.14688, 0.03057], dtype=float32))\n",
      "('Iter 4500:nmi = 0.36169, ari = 0.12283', ' ; loss=', array([0.04961, 0.14632, 0.03497], dtype=float32))\n",
      "('Iter 4800:nmi = 0.36363, ari = 0.12395', ' ; loss=', array([0.0781 , 0.14666, 0.06344], dtype=float32))\n",
      "('Iter 5100:nmi = 0.36631, ari = 0.12556', ' ; loss=', array([0.09129, 0.13099, 0.07819], dtype=float32))\n",
      "('Iter 5400:nmi = 0.36657, ari = 0.12567', ' ; loss=', array([0.0978 , 0.13382, 0.08442], dtype=float32))\n",
      "('Iter 5700:nmi = 0.36359, ari = 0.12431', ' ; loss=', array([0.09276, 0.12973, 0.07979], dtype=float32))\n",
      "('Iter 6000:nmi = 0.36467, ari = 0.12449', ' ; loss=', array([0.07643, 0.16462, 0.05997], dtype=float32))\n",
      "('Iter 6300:nmi = 0.36742, ari = 0.12585', ' ; loss=', array([0.10435, 0.16228, 0.08813], dtype=float32))\n",
      "('Iter 6600:nmi = 0.36828, ari = 0.12627', ' ; loss=', array([0.12399, 0.17179, 0.10681], dtype=float32))\n",
      "('Iter 6900:nmi = 0.37359, ari = 0.12830', ' ; loss=', array([0.04277, 0.14139, 0.02863], dtype=float32))\n",
      "('Iter 7200:nmi = 0.37897, ari = 0.13010', ' ; loss=', array([0.04765, 0.14062, 0.03358], dtype=float32))\n",
      "('Iter 7500:nmi = 0.37927, ari = 0.12977', ' ; loss=', array([0.07419, 0.13696, 0.06049], dtype=float32))\n",
      "('Iter 7800:nmi = 0.37898, ari = 0.13002', ' ; loss=', array([0.08756, 0.12957, 0.07461], dtype=float32))\n",
      "('Iter 8100:nmi = 0.37535, ari = 0.12849', ' ; loss=', array([0.09472, 0.1352 , 0.0812 ], dtype=float32))\n",
      "('Iter 8400:nmi = 0.38024, ari = 0.13071', ' ; loss=', array([0.0875 , 0.12573, 0.07493], dtype=float32))\n",
      "('Iter 8700:nmi = 0.37744, ari = 0.12925', ' ; loss=', array([0.07286, 0.16658, 0.0562 ], dtype=float32))\n",
      "('Iter 9000:nmi = 0.37815, ari = 0.12963', ' ; loss=', array([0.09603, 0.15674, 0.08035], dtype=float32))\n",
      "('Iter 9300:nmi = 0.37746, ari = 0.12912', ' ; loss=', array([0.11873, 0.15677, 0.10306], dtype=float32))\n",
      "('Iter 9600:nmi = 0.37932, ari = 0.13042', ' ; loss=', array([0.03988, 0.12548, 0.02734], dtype=float32))\n",
      "('Iter 9900:nmi = 0.38177, ari = 0.13109', ' ; loss=', array([0.04552, 0.12924, 0.0326 ], dtype=float32))\n",
      "('Iter 10200:nmi = 0.37983, ari = 0.13015', ' ; loss=', array([0.07102, 0.13048, 0.05797], dtype=float32))\n",
      "('Iter 10500:nmi = 0.38358, ari = 0.13230', ' ; loss=', array([0.08702, 0.13244, 0.07377], dtype=float32))\n",
      "('Iter 10800:nmi = 0.38278, ari = 0.13132', ' ; loss=', array([0.09016, 0.11701, 0.07846], dtype=float32))\n",
      "('Iter 11100:nmi = 0.37814, ari = 0.12876', ' ; loss=', array([0.08486, 0.12454, 0.07241], dtype=float32))\n",
      "('Iter 11400:nmi = 0.37929, ari = 0.12942', ' ; loss=', array([0.06745, 0.14659, 0.05279], dtype=float32))\n",
      "('Iter 11700:nmi = 0.38279, ari = 0.13102', ' ; loss=', array([0.09564, 0.16048, 0.07959], dtype=float32))\n",
      "('Iter 12000:nmi = 0.38488, ari = 0.13205', ' ; loss=', array([0.11802, 0.15593, 0.10242], dtype=float32))\n",
      "('Iter 12300:nmi = 0.38612, ari = 0.13241', ' ; loss=', array([0.03864, 0.11845, 0.0268 ], dtype=float32))\n",
      "('Iter 12600:nmi = 0.38713, ari = 0.13297', ' ; loss=', array([0.04532, 0.12788, 0.03253], dtype=float32))\n",
      "('Iter 12900:nmi = 0.38878, ari = 0.13315', ' ; loss=', array([0.06827, 0.12165, 0.0561 ], dtype=float32))\n",
      "('Iter 13200:nmi = 0.38752, ari = 0.13288', ' ; loss=', array([0.08309, 0.11488, 0.07161], dtype=float32))\n",
      "('Iter 13500:nmi = 0.38422, ari = 0.13075', ' ; loss=', array([0.08847, 0.11858, 0.07662], dtype=float32))\n",
      "('Iter 13800:nmi = 0.38564, ari = 0.13167', ' ; loss=', array([0.08288, 0.11692, 0.07118], dtype=float32))\n",
      "('Iter 14100:nmi = 0.38371, ari = 0.13062', ' ; loss=', array([0.06167, 0.1521 , 0.04646], dtype=float32))\n",
      "('Iter 14400:nmi = 0.38434, ari = 0.13065', ' ; loss=', array([0.08929, 0.13802, 0.07549], dtype=float32))\n",
      "('Iter 14700:nmi = 0.38514, ari = 0.13169', ' ; loss=', array([0.11705, 0.15142, 0.10191], dtype=float32))\n",
      "('Iter 15000:nmi = 0.38658, ari = 0.13222', ' ; loss=', array([0.04003, 0.12268, 0.02776], dtype=float32))\n",
      "('Iter 15300:nmi = 0.38624, ari = 0.13195', ' ; loss=', array([0.04389, 0.11237, 0.03265], dtype=float32))\n",
      "('Iter 15600:nmi = 0.38796, ari = 0.13301', ' ; loss=', array([0.06664, 0.11426, 0.05522], dtype=float32))\n",
      "('Iter 15900:nmi = 0.39093, ari = 0.13384', ' ; loss=', array([0.0842 , 0.12125, 0.07207], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=['kld', 'mse'], loss_weights=[0.1, 1], optimizer=pretrain_optimizer)\n",
    "\n",
    "for ite in range(int(maxiter)):\n",
    "    if ite % update_interval == 0:\n",
    "        q, _  = model.predict(x, verbose=0)\n",
    "        p = target_distribution(q)  # update the auxiliary target distribution p\n",
    "\n",
    "        # evaluate the clustering performance\n",
    "        y_pred = q.argmax(1)\n",
    "        if y is not None:\n",
    "            nmi = np.round(metrics.mutual_info_score(y, y_pred), 5)\n",
    "            ari = np.round(metrics.adjusted_rand_score(y, y_pred), 5)\n",
    "            loss = np.round(loss, 5)\n",
    "            print('Iter %d:nmi = %.5f, ari = %.5f' % (ite,nmi, ari), ' ; loss=', loss)\n",
    "\n",
    "        # check stop criterion\n",
    "        delta_label = np.sum(y_pred != y_pred_last).astype(np.float32) / y_pred.shape[0]\n",
    "        y_pred_last = np.copy(y_pred)\n",
    "        if ite > 0 and delta_label < tol:\n",
    "            print('delta_label ', delta_label, '< tol ', tol)\n",
    "            print('Reached tolerance threshold. Stopping training.')\n",
    "            break\n",
    "    idx = index_array[index * batch_size: min((index+1) * batch_size, x.shape[0])]\n",
    "    loss = model.train_on_batch(x=x[idx], y=[p[idx], x[idx]])\n",
    "    index = index + 1 if (index + 1) * batch_size <= x.shape[0] else 0\n",
    "\n",
    "model.save_weights(save_dir + '/b_DEC_model_final.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('nmi = 0.39003, ari = 0.13350', ' ; loss=', array([0.03656, 0.13965, 0.02259], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(save_dir + '/b_DEC_model_final.h5')\n",
    "q, _ = model.predict(x, verbose=0)\n",
    "p = target_distribution(q)  # update the auxiliary target distribution p\n",
    "\n",
    "# evaluate the clustering performance\n",
    "y_pred = q.argmax(1)\n",
    "if y is not None:\n",
    "    nmi = np.round(metrics.mutual_info_score(y, y_pred), 5)\n",
    "    ari = np.round(metrics.adjusted_rand_score(y, y_pred), 5)\n",
    "    loss = np.round(loss, 5)\n",
    "    print('nmi = %.5f, ari = %.5f' % (nmi, ari), ' ; loss=', loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
